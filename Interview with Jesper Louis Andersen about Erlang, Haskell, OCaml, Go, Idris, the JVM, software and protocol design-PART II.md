 # Interview with Jesper Louis Andersen about Erlang, Haskell, OCaml, Go, Idris, the JVM, software and protocol design — PART II

This is part II of the interview with [Jesper Louis Andersen](https://twitter.com/jlouis666). You can read [part I here.](https://medium.com/this-is-not-a-monad-tutorial/interview-with-jesper-louis-andersen-about-erlang-haskell-ocaml-go-idris-the-jvm-software-and-b0de06440fbd#.4gidstolk) This part of the interview is mostly about Erlang, one of my favorite languages. If you want to learn Erlang, take a look at [Spawned Shelter](http://spawnedshelter.com/), a website I made for Erlang newcomers.

Reach me via twitter at [@unbalancedparen](http://twitter.com/unbalancedparen) if you have any comment or interview request for [This is not a Monad tutorial](https://medium.com/this-is-not-a-monad-tutorial). **Stay tuned!**

![](https://miro.medium.com/max/405/1*DCzEYU60hk2pO7WCJj3GoQ.jpeg)

**What are the advantages of the Erlang VM over the JVM and vice versa?**
From a perspective of history, the choice of building the BEAM VM for Erlang was the correct one. Massive concurrency was less on the radar for many people, and Ericsson needed a platform which they controlled. Furthermore, the BEAM can exploit it is executing functional languages only: the GC needs no generation forward set for instance.

The roll-your-own-design decision has proven to be very valuable, even though compared to the JVM, the OTP team is far smaller. My guess is that for every hour sunk into BEAM, there is at least 15–20 hours of work in the JVM. In turn, there are things which you cannot do efficiently on the BEAM. It is still (2015) bytecode interpreted and has no JIT, which means raw execution of computationally intensive tasks is about 10–20 times slower than typical well-written Java. Projects such as Quasar/Pulsar and Akka promises Erlang-style concurrency on the JVM, but they are recently developed whereas the BEAM has been in production for many years.

The key differing design criteria comes from the design space originating in Bjarne Däcker’s thesis. Most notably the soft real-time constraints and the need for seamless hardware interaction, but also the need for running very large software systems in which feature interaction is complex. It turns out in such a world that the major problems are rarely raw execution speed, but rather how parts of the system operate as a coherent whole. Many of the problems in the design space requires a different approach than sheer execution brute force, especially in a multicore world. Had fast execution been important, it would have been addressed a long time ago. But it turns out every major release of BEAM provides a far more important set of new features. There is a lot of power in having a large industrial company backing the system, as the new features tend to be operational/industrial in nature.

The key difference in implementation is that the BEAM is built from the ground up as a resource sharing system, much like in an operating system. In an OS, two processes A and B are isolated and gets a fair share of the resources. If B is badly written, this has considerably less impact on A. Suppose for instance B has bad GC productivity and allocates a lot. Then the GC of B has to run far more often and B has to pay: either in lower throughput, or worse latency. At the same time, A will keep on running, without B having any bad impact on its operation. The BEAM isolates resources in such a way that a B application cannot directly impact an A application from a resource standpoint.

The contrast are systems where one large shared heap is used. They hedge both A and B on the same GC heap, hoping it is fast enough to power through. But clearly, a badly written B can affect a well written A far more. It matters in very-large-scale development since you cannot hope every part of the system is perfectly written.

**If the Erlang VM uses asynchronous I/O** **how does it do to present a normal api to the developer? Why aren’t callbacks needed like in Node.js?**

Node.js uses a cooperative scheduling algorithm as seen in old operating systems such as MacOS 9, Windows 95 running legacy 16-bit code, MS-DOS and so on. The method, in which the program explicitly yields the CPU for the next task, has a number of advantages: it is easy to adapt existing languages and systems to the method. It is highly efficient in throughput. And it allows you to “pack” lots of work into a single process.

The weakness of the cooperative model is its fragility in server settings. If one of the tasks in the task queue monopolizes the CPU, hangs or blocks, then the impact is worse throughput, higher latency, or a deadlocked server. The fragility has to be avoided in large-scale systems, so the Erlang runtime is built preemptively. The normal code is “instrumented” such that any call which may block automatically puts that process to sleep, and switches in the next one on the CPU. Furthermore, Erlang being functional, any process must loop by calling functions. An internal funcall counter measures “reductions” and once 2000 of these has been used, the process is forced off the CPU and the next one is switched in. The process is entirely automatic and follows the modern idea of time-sharing in operating systems: AmigaOS, UNIX, Windows NT+, and so on.

`Note that in Erlang there is _no way_ to call blocking operations at all, since they are all handled by the runtime. This means the model is coherent and I can use any library I like without fear of it doing something bad (Top highlight).`  As an example, BEAM uses its own PCRE Regex library which cooperatively yields expensive NFA traversals. It also breaks up expensive crypto-computations, long-running GCs, and costly term serializations. It even includes a blocking monitor built-in so you can get notified if a monopolization has happened. Calls to foreign code written in C is harder though, since you have to take i
